{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"21_MNIST_Train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Dv8Rjd6TYxaY"},"source":["# PyTorch 初心者ハンズオン\n","\n","## PytorchによるNNの訓練\n","\n","ここでは、MNISTと呼ばれる、よく知られる手書き文字データ・セットによって、NNの流れを体感していただきましょう。\n","\n","## ページ内目次\n","\n","<ul>\n","    <li>\n","        <a href=\"#PyTorchによるNNの訓練\">PyTorchによるNNの訓練</a>\n","        <ul>\n","            <li><a href=\"#PyTorchのインポート、MNISTデータセットの読み込み\">PyTorchのインポート、MNISTデータセットの読み込み</a></li>\n","            <li><a href=\"#NNの構造定義\">NNの構造定義</a></li>\n","            <li><a href=\"#NN訓練前の準備\">NN訓練前の準備</a></li>\n","            <li><a href=\"#NNの訓練\">NNの訓練</a></li>\n","        </ul>\n","    <li>\n","        <a href=\"#生成モデルによる出力の理解\">生成モデルによる出力の理解</a>\n","        <ul>\n","            <li><a href=\"#訓練したモデルを用いた予測\">訓練したモデルを用いた予測</a></li>\n","            <li><a href=\"#出力値による割当クラスの決定\">出力値による割当クラスの決定</a></li>\n","        </ul>\n","    <li>\n","        <a href=\"#softmax関数の利用\">softmax関数の利用</a>\n","        <ul>\n","            <li><a href=\"#Softmax関数を試してみる\">Softmax関数を試してみる</a></li>\n","            <li><a href=\"#Softmax関数を試してみる（注意点）\">Softmax関数を試してみる（注意点）</a></li>\n","            <li><a href=\"#ユーティリティ関数の定義\">ユーティリティ関数の定義</a></li>\n","        </ul>\n","    </li>\n","</ul>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WhYgtgjdYxaf"},"source":["<hr>\n","\n","## PyTorchによるNNの訓練\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kVUM6kB1Yxaf"},"source":["下記構造のNNを、 MNIST データセットで訓練していきます。"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oxfQKl9jYxag"},"source":["<img src=\"_images/mlp_class.png\">"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PyVZJfKWYxah"},"source":["入力値として手書き文字画像を与え、出力値として正しいクラスラベルを得ることが最終的な訓練の目的です。 <br>\n","たとえば、 9 の手書き文字を入力したら、 9 というクラスラベルが出力されるよう、ニューラルネットワークを訓練します。"]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"8rmEntYYYxai"},"source":["<hr>\n","\n","## PyTorchのインポート、MNISTデータセットの読み込み"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WiGbPHFXYxai"},"source":["最初に、今回利用する各種モジュールをインポートしておきます。\n","* NumPy （数値演算ライブラリ）\n","* matplotlib （グラフ描画ライブラリ）\n","* chainer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_17H9ta5Yxaj","colab":{}},"source":["import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import torch as t\n","import torchvision as tv"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8HmTHORXYxal"},"source":["MNISTデータセット（訓練用データ、および評価用データ）をロードする"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gAFQZRMgj_Bq","colab":{}},"source":["preprocess = tv.transforms.Compose([\n","                                    tv.transforms.ToTensor(),\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lr_zq31NYxal","colab":{}},"source":["trainset = tv.datasets.MNIST('~/tmp/mnist', \n","                               train=True,\n","                               download=True,\n","                               transform=preprocess)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xpwvo_t3j2hI","colab":{}},"source":["testset = tv.datasets.MNIST('~/tmp/mnist',\n","                              train=False,\n","                              download=True,\n","                              transform=preprocess)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rxLAdigOYxan"},"source":["<hr>\n","\n","## NNの構造定義"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a6hTKGI2uerT","colab":{}},"source":["device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n","device"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"S8o8xDYRlSec","colab":{}},"source":["from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nHZa1I2xm1co"},"source":["では、入力が784次元、出力が10次元のNNをクラス定義します。\n","\n","PyTorchの世界では、NNを構築するクラスはtorch.nn.Moduleを継承している必要があります。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ck6yqAaWYxao","colab":{}},"source":["class MLP(nn.Module):\n","\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        # the size of the inputs to each layer will be inferred\n","        self.l1 = nn.Linear(784, 1000)    # n_in -> n_units\n","        self.l2 = nn.Linear(1000, 1000)  # n_units -> n_units\n","        self.l3 = nn.Linear(1000, 10)     # n_units -> n_out\n","\n","    def forward(self, x):\n","        h = x.view(-1, 28*28) # (N, 1, 28, 28) -> (N, 784)\n","        # １層目\n","        h = F.relu(self.l1(h))\n","        # ２層目\n","        h = F.relu(self.l2(h))\n","        # 出力層\n","        return self.l3(h)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9t3nGj2nPeU4"},"source":["MPLのNNを変数宣言しておく。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rfEOhRbkt4e9","colab":{}},"source":["model = MLP()\n","model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lONUmemKzA1q"},"source":["これで定義したNNを用いた分類器の完成です。\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"5nKMgKvHYxaq"},"source":["<hr>\n","\n","## NN訓練前の準備"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c57B5BN1z5Vu"},"source":["オプティマイザ（誤差最小化アルゴリズム）を準備します。\n","\n","> 説明は省略"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Tj524PFjzyLf","colab":{}},"source":["from torch import optim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jNmORAxwsC9G","colab":{}},"source":["optimizer = optim.Adam(model.parameters(), lr=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xk9JKM_g1TLU"},"source":["イテレータを準備します。\n","\n","このイテレータによって、batchsize単位で訓練サンプルが取得できます。  \n","ランダムに取得することもできますが、再現性がなくなるので講義である今回はOFFにしておきましょう。\n","\n","> Chainerで言えばiteratorを返すupdaterみたいなモノ"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uw2rj9y41a5v","colab":{}},"source":["batchsize=100\n","train_loader = t.utils.data.DataLoader(trainset,\n","                         batch_size=batchsize,\n","                         shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EbB_CbqlALQn"},"source":["最後にlossを計算する関数を定義しておきます。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QCHWLCvWAK4N","colab":{}},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cmkQou1GYxas"},"source":["<hr>\n","\n","## NNの訓練"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jUb3fORYYxas"},"source":["ここまでで、NNを訓練する準備ができました。\n","\n","ここでの訓練内容は、 trainset データセットにある入力値（28x28画像を784次元にしたもの）および目標値（0〜9のクラスラベル）を用いて、新たな入力値に対する予測値を求めることです。"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aFV3v-1qYxat"},"source":["訓練処理を、下記の通り実行します。\n","\n","* 訓練前に、第1層の重み情報を画像として表示します。  \n","   > NNでは、訓練前の重み情報はランダムに設定されます。  \n","   > これは先入観を表していると捉えてもらえればいいです。\n","* 訓練を実行します。\n","* 訓練後、第1層の重み情報を画像として表示します。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FpyjvzfM8OlS","colab":{}},"source":["param_dict_before = model.state_dict()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oFFyjiNM_Qeg"},"source":["１層目の重みを保存しておきます。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1sX5b2ge_Tfq","colab":{}},"source":["l1w_before = param_dict_before[\"l1.weight\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yrd_wbdsDP78","colab":{}},"source":["import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"H85Fe2r2c9R6"},"source":["次のセルは実行表示が、しばらくの間 ```In [*]```となっているはずです。  \n","訓練には時間がかかるため、完了するまでしばらく待ちましょう。\n","\n","> - CPUの場合、約3sec/枚 \n","> - GPUの場合、約1sec/枚"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jipFIjU75VSm","colab":{}},"source":["def dev_env(tensor):\n","      return \"cuda\" if tensor.is_cuda else \"cpu\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n32gXf9qYxat","colab":{}},"source":["epochs=20\n","model.train() # トレーニングモードに遷移\n","criterion = criterion.to(device)\n","model = model.to(device) # GPUへ転送\n","for epoch in range(epochs):\n","    running_loss = 0.0\n","    start = time.time()\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs.to(device))\n","        loss = criterion(outputs, labels.to(device))\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 100 == 99:\n","            end = time.time()\n","            print('[{:d}, {:5d}] loss: {:.3f} (elapsed: {:.1f} [s] by {})'\n","                    .format(epoch + 1, i + 1, running_loss / 100, end-start, dev_env(outputs)))\n","            running_loss = 0.0\n","            start = time.time()\n","print('Finished Training')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"e4NjNm0IcoL2"},"source":["学習結果はGPU側のメモリに保存されているため、取り出す場合にはモデルデータをCPU側に転送する必要がある。  \n","ここでは、明示的に`cpu`メソッドをコールすることで解決します。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8ZREHf_vcntd","colab":{}},"source":["model = model.cpu()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PzkugIza_fO-","colab":{}},"source":["param_dict_after = model.state_dict()\n","l1w_after = param_dict_after[\"l1.weight\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Lxh14icVYxav"},"source":["訓練前と訓練後の重み画像を比較してみましょう。  \n","この画像から直接読み取れることは少ないですが、訓練を通じてモデル内のパラメータが変化したことが読み取れれば十分です。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HHfaAqysY2O0","colab":{}},"source":["fig, ax = plt.subplots(1,2, figsize=(10, 10))\n","# 訓練前のL1重みを画像として表示\n","ax[0].set_title(\"Layer1's weight [BEFORE]\")\n","ax[0].imshow(l1w_before)\n","# 訓練前のL1重みを画像として表示\n","ax[1].set_title(\"Layer1's weight [AFTER]\")\n","ax[1].imshow(l1w_after)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VjGsWO0jYxav"},"source":["<hr>\n","\n","# 生成モデルによる出力の理解"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YgXiPBDNYxaw"},"source":["<div style=\"border: 1px solid; padding: 10px\">\n","<p>さきほど、MNISTデータセットを用いて手書き画像を分類するためのNNを訓練しました。</p>\n","<p>続けて、訓練したモデルによる予測を試みます。</p>\n","<ul><li>MNISTデータセットのテスト用サンプルデータを入力し、出力を得る</li>\n","<li>出力から、どのクラスに予測されたか確認する</li>\n","<li>サンプルの画像、目標値、予測値の関係を確認する</li>\n","</ul>\n","</div>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4bU6los1Yxaw"},"source":["<hr>\n","\n","## 訓練したモデルを用いた予測"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"60jDsdZKiNAf"},"source":["今から予測フェイズになります。  \n","モデルを訓練モードから評価モードにしましょう。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9tTQdVMNiMzZ","colab":{}},"source":["model = model.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FJ_5mXyMYxax"},"source":["test_index 番目のテストデータの画像をNNに入力し、出力 y を得る"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R9M0f8YcifQi","colab":{}},"source":["test_index=99\n","target = testset[99]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vd5hOMhLjIeT","colab":{}},"source":["input_tensor = target[0]\n","input_tensor.is_cuda"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XNDadgiAig91","colab":{}},"source":["input_tensor.unsqueeze_(0)\n","input_tensor.size()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MF2_HsBdi75g","colab":{}},"source":["p = model(Variable(input_tensor))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QqI8S-67p2KW"},"source":["<hr>\n","\n","## 出力値による割当クラスの決定"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7mrxVh4QmSqg"},"source":["予測結果が持つdataメンバの形に注意。  \n","複数の入力を受けて複数の出力を出すために、二次元配列になっている。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aRndo2GPmFAP","colab":{}},"source":["p.data.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5JI9OIzBmg_p"},"source":["二次元配列ということを念頭に入れてdata[0]でアクセスすること。\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4ew-2yT8jEWQ","colab":{}},"source":["d = p.data[0]\n","softmax_d = F.softmax(d, dim=0)\n","data_volume = len(d)\n","\n","fig, ax = plt.subplots(1,2, figsize=(10, 5))\n","# 確率グラフを表示\n","ax[0].set_title(\"Prediction\")\n","ax[0].set_xticks(np.arange(0, data_volume, 1))\n","ax[0].bar(x=range(data_volume), height=softmax_d)\n","# 画像データを表示\n","ax[1].set_title(\"Image\")\n","ax[1].imshow(target[0].reshape(28,28))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jnMdEw5IYxa9"},"source":["最も出力値が大きな要素を予測ラベルとして採用する\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"blQkX3lOYxa-","colab":{}},"source":["predicted_label = np.argmax(softmax_d)\n","predicted_label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Fo3MOboBYxbH"},"source":["<hr>\n","【演習】<br>\n","\n","* 自由に test データセットからサンプルを選び、予測結果を確認してください。\n","* この予測は 100% 正解にはなりません。色々なサンプルデータを試すと、予測結果が間違っているものも見つかるはずです。"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rZTvYyD8YxbH","colab":{}},"source":["# 演習\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X7ydXOB-YxbJ"},"source":["<hr>\n","\n","【演習】\n","\n","* <a href=\"#NN訓練前の準備\">NN訓練前の準備</a>まで戻り、パラメータを変えて訓練、および、ここまでの確認項目をやり直してみてください。\n","   * epoch=1, batchsize=60000 で訓練し、予測結果がどうなるかを確認してください。 <br> この設定では訓練による重みの調整回数が減少するため、特に予測ミスが発生しやすくなります。\n","   * ブラウザの別タブなどで実行することにより2回の実行を横に並べて見比べるとよいでしょう。\n","   * （ランダムに学習されるため、毎回違う画像になりますが） epoch によって重みデータ画像の雰囲気が変化するはずです。\n","   * epoch=1とepoch=20でNNが出力する値にどのような違いがありますか。\n","   * epoch が大きいほど、NNの出力値の各要素は 0 もしくは 1 に近づいていきます。これは何故ですか。\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JCxaX1NAYxbK"},"source":["訓練済みネットワークの出力値はスケールや範囲がまちまちです。\n","\n","モデル自体は、 one-hot encoding によって、非正解が0, 正解が 1 になるように訓練しますが、 0 や 1 の値が返されるとはかぎりません（今回の問題は簡単なため、ちょっと長く訓練すれば 0 や 1 に近くなりますが、実際にはマイナス値をふくむ、もっと不安定な値が返されることのほうが多いです）。このため、分類問題においてNNの出力値そのままでは扱いづらい、といえます。\n","\n","Softmax関数は、NNの出力ユニットの値をおよそ 0.00 ~ 1.00 の範囲に押さえ込み、確率として扱える値に変換します。"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X-1_sDh2YxbK"},"source":["<hr>\n","\n","## Softmax関数を試してみる"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uZPf_0YSYxbK","colab":{}},"source":["y = t.tensor([1.0,1.0,1.0])\n","F.softmax(y, dim=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZbH0WFKlYxbM","colab":{}},"source":["y  = t.tensor([1.0, 2.0, 7.0])\n","F.softmax(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WWQiQV-_YxbN","colab":{}},"source":["y = t.tensor([1.0, -5.0, 2.0])\n","F.softmax(y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yGVkvF6vYxbO"},"source":["## Softmax関数を試してみる（注意点）"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kaSZ3MuCYxbP"},"source":["One-hot encoding の値がどのような確率に変換されるかを確認する"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1576750333417,"user_tz":-540,"elapsed":857,"user":{"displayName":"コウ","photoUrl":"","userId":"15615658067056912208"}},"id":"ieEcnXn3YxbP","outputId":"41a58892-079a-4ffe-c1d9-94287f137822","colab":{"base_uri":"https://localhost:8080/","height":180}},"source":["y = t.tensor([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n","F.softmax(y)"],"execution_count":44,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-a431e7fbc141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 't' is not defined"]}]},{"cell_type":"code","metadata":{"id":"Sh05TBIupLow","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}